{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Spam Filter\n",
    "\n",
    "Code largely based on Joel Grus' *Data Science from Scratch*, page 168 (O'Reilly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import re\n",
    "\n",
    "class NaiveBayesSpamFilter():\n",
    "   \n",
    "    # Pipeline\n",
    "    def train(self, training_set, k=0.1):\n",
    "        \"\"\"Train classifier with training_set of form (String MESSAGE, Boolean ISSPAM)\"\"\"\n",
    "        # Count spam and non-spam messages\n",
    "        num_spam = sum([1 if is_spam else 0 for message, is_spam in training_set])\n",
    "        num_not_spam = len(training_set) - num_spam\n",
    "        # Run data through our pipeline\n",
    "        word_counts = self.count_words(training_set)\n",
    "        self.word_probs = self.word_probabilities(word_counts, num_spam, num_not_spam, k)\n",
    "    def classify(self, message):\n",
    "        try:\n",
    "            return self.spam_probability(self.word_probs, message)\n",
    "        except:\n",
    "            print(\"You must train first!\")\n",
    "    \n",
    "    #Functions for pipeline\n",
    "    def tokenize(self,message):\n",
    "        \"\"\"Return unique words in message\"\"\"\n",
    "        return set(re.findall(\"[a-z0-9']+\", message.lower()))\n",
    "    def count_words(self,training_set):\n",
    "        \"\"\"Returns defaultdict of form {WORD:[SPAM_COUNT,NON_SPAM_COUNT]}. training_set consists of tuples (MESSAGE,IS_SPAM)\"\"\"\n",
    "        counts = defaultdict(lambda : [0,0]) # Associate each word with a spam count and non-spam count\n",
    "        for message, is_spam in training_set:\n",
    "            for word in self.tokenize(message):\n",
    "                counts[word][0 if is_spam else 1] += 1\n",
    "        return counts\n",
    "    def word_probabilities(self, count, total_spams, total_non_spams, k):\n",
    "        \"\"\"Return list of tuples (word, P(W|Spam), P(W|~Spam))\"\"\"\n",
    "        word_probs = []\n",
    "        for w, (spam, non_spam) in count.iteritems():\n",
    "            p_word_given_spam = (spam + k) / (total_spams + 2*k) # Use of 'k' is to prevent any 0's in probabilities\n",
    "            p_word_given_non_spam = (non_spam + k) / (total_non_spams + 2*k)\n",
    "            word_probs.append((w,p_word_given_spam,p_word_given_non_spam))\n",
    "        return word_probs\n",
    "    def spam_probability(self,word_probs, message):\n",
    "        \"\"\"List of word probability tuples and one message, return P(Spam|all_word_in_message)\"\"\"\n",
    "        message_words = self.tokenize(message)\n",
    "        log_prob_given_spam = log_prob_given_not_spam = 0.0\n",
    "        for word, prob_given_spam, prob_given_not_spam in word_probs:\n",
    "            if word in message_words:\n",
    "                # Since we are using log probabilities, we add rather than multiply the log of each word's prob\n",
    "                # i.e., p(all_word|spam) = p(w1|spam)*p(w2|spam)*... = exp(log(p(w1|spam)) + log(p(w2|spam)) + ...)\n",
    "                log_prob_given_spam += math.log(prob_given_spam)\n",
    "                log_prob_given_not_spam += math.log(prob_given_not_spam)\n",
    "            else:\n",
    "                # If we don't see one of our training words in the message,\n",
    "                # add the corresponding probability for not seeing it\n",
    "                # i.e. log(1-probability)\n",
    "                log_prob_given_spam += math.log(1.0-prob_given_spam)\n",
    "                log_prob_given_not_spam += math.log(1.0-prob_given_not_spam)\n",
    "        prob_given_spam = math.exp(log_prob_given_spam)\n",
    "        prob_given_not_spam = math.exp(log_prob_given_not_spam)\n",
    "        # Bayes thm simplified with the (naive) assumption P(S) = P(~S)\n",
    "        # Bayes thm: P(A|B) = P(B|A)P(B) / (P(A|B)P(B) + P(A|~B)P(~B))\n",
    "        return prob_given_spam / (prob_given_spam + prob_given_not_spam) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now let's test it with a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability our message 'Click the link for free viagra and a rolex' is spam: 0.999993990673\n",
      "Probability our message 'Hello friend!' is spam: 0.0637988267127\n"
     ]
    }
   ],
   "source": [
    "# 3 spam messages, 2 non-spam messages\n",
    "message_samples = [(\"Hello, this is an ordinary message\", False), (\"free viagra!\", True), \n",
    "                   (\"FREE rolex\", True), (\"FREE money!\", True), (\"Happy holidays\", False)]\n",
    "# Create and train\n",
    "spamfilter = NaiveBayesSpamFilter()\n",
    "spamfilter.train(message_samples)\n",
    "\n",
    "# The examples we try to classify\n",
    "sample_spam_message = \"Click the link for free viagra and a rolex\"\n",
    "sample_non_spam_message = \"Hello friend!\"\n",
    "\n",
    "print(\"Probability our message '{0}' is spam: {1}\".format(sample_spam_message, spamfilter.classify(sample_spam_message)))\n",
    "print(\"Probability our message '{0}' is spam: {1}\".format(sample_non_spam_message, spamfilter.classify(sample_non_spam_message)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our model\n",
    "\n",
    "Now let's test on a larger dataset of emails from *http://spamassassin.apache.org/publiccorpus/* \n",
    "\n",
    "We will train and classify emails based only on the *subject*, using it as the \"message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To rerun make sure '20021010_easy_ham.tar.bz2' and '20021010_spam.tar.bz2' are in your relative path\n",
    "import bz2\n",
    "import re\n",
    "\n",
    "non_spam = bz2.BZ2File('20021010_easy_ham.tar.bz2').readlines()\n",
    "spam = bz2.BZ2File('20021010_spam.tar.bz2').readlines()\n",
    "\n",
    "all_messages = []\n",
    "for line in non_spam:\n",
    "    if line.startswith(\"Subject:\"):\n",
    "        message = re.sub(r\"^Subject: \", \"\", line).strip()\n",
    "        all_messages.append((message,False))\n",
    "for line in spam:\n",
    "    if line.startswith(\"Subject:\"):\n",
    "        message = re.sub(r\"^Subject: \", \"\", line).strip()\n",
    "        all_messages.append((message,True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all our messages in the form [(String MESSAGE, Boolean ISSPAM),...] as required.\n",
    "\n",
    "Let's take a brief look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spam messages: 503\n",
      "A spam message:Want to play poker with other people online.\n",
      "\n",
      "Total non-spam messages: 2651\n",
      "A non-spam message:RE: The Curse of India's Socialism\n",
      "\n",
      "Total examples: 3154\n"
     ]
    }
   ],
   "source": [
    "total_messages = len(all_messages)\n",
    "total_spam = len([message for message, isspam in all_messages if isspam == True])\n",
    "total_non_spam = total_messages - total_spam\n",
    "\n",
    "print(\"Total spam messages: \" + str(total_spam))\n",
    "print(\"A spam message:\" + all_messages[-1][0])\n",
    "print(\"\\nTotal non-spam messages: \" + str(total_non_spam))\n",
    "print(\"A non-spam message:\" + all_messages[0][0])\n",
    "print(\"\\nTotal examples: \" + str(total_messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we shuffle and split up our data into training (75%) and testing (25%) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(all_messages)\n",
    "training_set = all_messages[:2300]\n",
    "testing_set = all_messages[2300:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.909836065574\n",
      "\n",
      "Some mis-labeled emails:\n",
      "\n",
      "Real Label\tP(S)\tMessage\n",
      "Spam:\t\t0.373\t[scoop] Haberdar olun\n",
      "Non-Spam:\t0.655\tTurning junk computers into activist gold\n",
      "Spam:\t\t0.034\tre: domain registration savings\n",
      "Spam:\t\t0.472\tHottest babes!                                                       4139YAEk3--9\n",
      "Spam:\t\t0.042\t[scoop] ....It is not my fault. .- vwiid\n"
     ]
    }
   ],
   "source": [
    "spamfilter = NaiveBayesSpamFilter()\n",
    "spamfilter.train(training_set)\n",
    "\n",
    "total_correct = 0.0 # Tally up correctly classified emails\n",
    "mis_labeled = [] # To hold mis-labeled emails\n",
    "\n",
    "for message, isspam in testing_set:\n",
    "    p_spam = spamfilter.classify(message)\n",
    "    label = (p_spam > .5)\n",
    "    if(label == isspam):\n",
    "        total_correct+=1\n",
    "    else:\n",
    "        mis_labeled.append((message,isspam, p_spam))\n",
    "        \n",
    "print(\"Model accuracy: {}\".format(total_correct/len(testing_set)))\n",
    "\n",
    "print(\"\\nSome mis-labeled emails:\\n\")\n",
    "print(\"Real Label\\tP(S)\\tMessage\")\n",
    "for i in range(5):\n",
    "    label = (\"Spam:\\t\\t\" if mis_labeled[i][1] else \"Non-Spam:\\t\")\n",
    "    print(label + str(round(mis_labeled[i][2],3)) + \"\\t\" + mis_labeled[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
